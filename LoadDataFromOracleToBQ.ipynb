{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51ee8ceb-2e4e-4bf2-a571-acd97c73a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "import os\n",
    "\n",
    "import cx_Oracle\n",
    "import sqlalchemy\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "#https://github.com/technqvi/SMart-AI/blob/main/LoadIncident_PostgresToBQ.ipynb\n",
    "#https://github.com/technqvi/AlertPriceInRange/blob/master/price_range_notification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14e6355-af8c-46d7-8cbe-6f6fdd0000df",
   "metadata": {},
   "source": [
    "# Init constant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8121238b-8a75-46d6-8886-d1fc88880f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_name=\"yip_ar_receipt\"\n",
    "source_name=\"yip_invoice_monthly\"\n",
    "init_date_query='2020-01-01'\n",
    "# set True whatever , you want to reload all items\n",
    "isLoadingAllItems=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5850bfd-8dd0-4bb2-bbc2-8f704ee0a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "listError=[]\n",
    "\n",
    "projectId='mismgntdata-bigquery'\n",
    "region='asia-southeast1'\n",
    "dataset_id='MIS_BI_DW'\n",
    "table_id = f\"{projectId}.{dataset_id}.{source_name}\"\n",
    "\n",
    "_ip='172.30.57.10'\n",
    "_hostname='YIPGERP'\n",
    "_port=1521\n",
    "_servicename='PROD'\n",
    "_username='yipgbi'\n",
    "_password='yipgbi'\n",
    "\n",
    "\n",
    "data_base_file=r'D:\\ETL_Orable_To_BQ\\etl_web_admin\\etl_config_transaction.db'\n",
    "sqlite3.register_adapter(np.int64, lambda val: int(val))\n",
    "sqlite3.register_adapter(np.int32, lambda val: int(val))\n",
    "\n",
    "json_credential_file=r'C:\\Windows\\mismgntdata-bigquery--bq-loader-34713c332847.json'\n",
    "\n",
    "temp_path=f'temp/{source_name}.csv'\n",
    "\n",
    "\n",
    "start_date_query=''\n",
    "updateCol='last_update_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b81b25c9-9ca4-4a92-8a0b-56b744c1cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 11:43:35\n",
      "2023-05-30 11:43:35\n"
     ]
    }
   ],
   "source": [
    "dt_imported=datetime.now()\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#dtStr_imported='2023-05-23 23:00:00'\n",
    "\n",
    "dt_imported=datetime.strptime(dtStr_imported,\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(dtStr_imported)\n",
    "print(dt_imported)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f042ef-0a73-42e0-8f4a-d8abb35c86e4",
   "metadata": {},
   "source": [
    "# Manage Log Error Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b133498e-6330-40ce-8d7f-4c00eeab1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logErrorMessage(errorList):\n",
    "    def logError(recordList):\n",
    "        try:\n",
    "            sqliteConnection = sqlite3.connect(os.path.abspath(data_base_file))\n",
    "            cursor = sqliteConnection.cursor()\n",
    "            sqlite_insert_query = \"\"\"\n",
    "            INSERT INTO log_error\n",
    "            (error_datetime,etl_datetime, data_source_id,message)  VALUES (?,?,?,?);\n",
    "             \"\"\"\n",
    "            cursor.executemany(sqlite_insert_query, recordList)\n",
    "            print(\"Done Log Error\")\n",
    "            sqliteConnection.commit()\n",
    "            cursor.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)]) \n",
    "            logErrorMessage(listError)\n",
    "        finally:\n",
    "            if sqliteConnection:\n",
    "                sqliteConnection.close()\n",
    "            \n",
    "    if len(errorList)>0:\n",
    "        error_message=f\"{source_name} ETL at {dt_imported} raise some errors.\"\n",
    "        print(error_message)\n",
    "        \n",
    "        dfError=pd.DataFrame(data=errorList,columns=[\"error_datetime\",\"etl_datetime\",\"data_source_id\",\"message\"])\n",
    "        print(dfError)\n",
    "        logError(dfError.to_records(index=False))\n",
    "        \n",
    "        error_message=f\"{source_name} ETL at {dt_imported} raise some errors.\"\n",
    "        \n",
    "        # send email to admin\n",
    "        raise  Exception(error_message)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cada0-53c7-4004-ab0e-29bb8a3683b0",
   "metadata": {},
   "source": [
    "# Get & Set Oracle ViewName and other configuration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "699f0142-e421-4899-ae80-687c39a0ccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from data_source where id='yip_invoice_monthly'  \n"
     ]
    }
   ],
   "source": [
    "# get data from data_source\n",
    "def get_ds(data_source_name):\n",
    "   try: \n",
    "        conn = sqlite3.connect(os.path.abspath(data_base_file))\n",
    "        sql_ds=f\"\"\"select * from data_source where id='{data_source_name}'  \"\"\"\n",
    "        print(sql_ds)\n",
    "        df_item=pd.read_sql_query(sql_ds, conn)\n",
    "        if df_item.empty==False:\n",
    "           return df_item.iloc[0,:]\n",
    "        else:\n",
    "           return None\n",
    "   except Exception as e:\n",
    "       listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)]) \n",
    "       logErrorMessage(listError)\n",
    "    \n",
    "ds_item=get_ds(source_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e6b500f-a80e-4910-ac1a-15d40a2974d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data source config data\n",
      "Column to load at first = invoice_date\n",
      "Partition : invoice_date - MONTH\n",
      "['invoice_date', 'gl_date', 'dept_name', 'cust_name']\n",
      "['gl_date', 'invoice_date']\n"
     ]
    }
   ],
   "source": [
    "if ds_item is not None:\n",
    "    print(\"Load data source config data\")\n",
    "\n",
    "    colFirstLoad=ds_item['first_load_col']\n",
    "    print(f\"Column to load at first = {colFirstLoad}\")\n",
    "\n",
    "    partitionCol=ds_item['partition_date_col']  # required DateTime Type\n",
    "    if   ds_item['partition_date_type']==\"DAY\":\n",
    "     partitionType=bigquery.TimePartitioningType.DAY\n",
    "    elif ds_item['partition_date_type']==\"MONTH\":\n",
    "     partitionType=bigquery.TimePartitioningType.MONTH    \n",
    "    elif ds_item['partition_date_type']==\"YEAR\":\n",
    "     partitionType=bigquery.TimePartitioningType.YEAR   \n",
    "    else:\n",
    "     partitionType=bigquery.TimePartitioningType.DAY\n",
    "    \n",
    "    print(f\"Partition : {partitionCol} - {partitionType}\")\n",
    "    \n",
    "        \n",
    "    if ds_item['cluster_col_list']=='':\n",
    "     clusterCols=[]   \n",
    "     print(f\"{clusterCols} (No cluster cols)\")   \n",
    "     \n",
    "    else:\n",
    "     clusterCols=  ds_item['cluster_col_list'].split(',') \n",
    "     clusterCols = list(map(str.strip,clusterCols))\n",
    "     print(clusterCols)\n",
    "\n",
    "    if ds_item['date_col_list']=='':\n",
    "     dateCols=[]   \n",
    "     print(f\"{dateCols} (No Date cols)\")   \n",
    "     \n",
    "    else:\n",
    "     dateCols=  ds_item['date_col_list'].split(',') \n",
    "     dateCols = list(map(str.strip,dateCols))\n",
    "     print(dateCols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7fbc6-59e4-4dee-8a60-b9d7bf24df6a",
   "metadata": {},
   "source": [
    "# List Last ETL Transacton by Datasource Name\n",
    "### Get last etl of the specific view to perform incremental update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7dc53a9-342c-4e67-a9ad-85c249845fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload all data:  2020-01-01\n"
     ]
    }
   ],
   "source": [
    "def get_last_etl_by_ds(data_source):\n",
    "   try: \n",
    "    conn = sqlite3.connect(os.path.abspath(data_base_file))\n",
    "    sql_last_etl=f\"\"\"select etl_datetime,data_source_id from etl_transaction where data_source_id='{data_source}' \n",
    "    order by etl_datetime desc limit 1\n",
    "    \"\"\"\n",
    "    print(sql_last_etl)\n",
    "    df_item=pd.read_sql_query(sql_last_etl, conn)\n",
    "    print(df_item)\n",
    "    return df_item\n",
    "    \n",
    "   except Exception as e:\n",
    "       listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)]) \n",
    "       logErrorMessage(listError)\n",
    "\n",
    "if isLoadingAllItems==False:\n",
    "    dfLastETL=get_last_etl_by_ds(source_name)\n",
    "    if dfLastETL.empty==False:\n",
    "      start_date_query=dfLastETL.iloc[0,0]\n",
    "      print(f\"Start Import on update_at of last ETL date :  {start_date_query}\" ) \n",
    "    else:\n",
    "       isLoadingAllItems=True \n",
    "       start_date_query=init_date_query\n",
    "       print(f\"No etl transaction , we will get started with importing all items from :  {start_date_query}\" ) \n",
    "else:\n",
    "   start_date_query=init_date_query\n",
    "   print(f\"Reload all data:  {start_date_query}\" ) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233d732-e586-4138-8241-45ea7df0c9b4",
   "metadata": {},
   "source": [
    "# Load data from Oracel  as DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "834285ba-52c9-4449-91cd-be7f7cbe10e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from yip_invoice_monthly   \n",
      "           where  invoice_date>=to_date('2020-01-01','yyyy-mm-dd') \n",
      "           \n"
     ]
    }
   ],
   "source": [
    "def loadData(isReLoadAll):\n",
    "    try:\n",
    "       engine = sqlalchemy.create_engine(f\"oracle+cx_oracle://{_username}:{_password}@{_ip}:{_port}/?service_name={_servicename}\")\n",
    "       if isReLoadAll==True:\n",
    "         sql=f\"\"\"select * from {source_name}   \n",
    "           where  {colFirstLoad}>=to_date('{start_date_query}','yyyy-mm-dd') \n",
    "           \"\"\"    \n",
    "       else:    \n",
    "           sql =f\"\"\"select * from {source_name}   \n",
    "           where  {updateCol}>=to_date('{start_date_query}','yyyy-mm-dd hh24:mi:ss') \"\"\"\n",
    "\n",
    "       print(sql)\n",
    "       dfAll = pd.read_sql(sql, engine)\n",
    "       dfAll['ImportedAt']=dt_imported \n",
    "       return dfAll \n",
    "    except Exception as e:\n",
    "       listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)])\n",
    "       logErrorMessage(listError)\n",
    "    \n",
    "\n",
    "dfAll=loadData(isLoadingAllItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea247b06-3a51-4132-be26-79cd281ba16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_trx_id', 'org_id', 'gl_date', 'invoice_date', 'dept_name', 'dept_code', 'invoice_number', 'tax_invoice_number', 'so', 'project', 'rev_con', 'cn_number', 'cn_comment', 'invoice_type', 'invoice_type_description', 'cust_code', 'cust_name', 'industry_new', 'sector', 'abbrevation', 'sale_code', 'sale_name', 'invoice_amount', 'total_cost', 'margin_amount', 'margin_percent', 'creation_date', 'created_by', 'last_update_date', 'last_updated_by', 'ImportedAt']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22113 entries, 0 to 22112\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   customer_trx_id           22113 non-null  int64         \n",
      " 1   org_id                    22113 non-null  int64         \n",
      " 2   gl_date                   22113 non-null  datetime64[ns]\n",
      " 3   invoice_date              22113 non-null  datetime64[ns]\n",
      " 4   dept_name                 22113 non-null  object        \n",
      " 5   dept_code                 22113 non-null  object        \n",
      " 6   invoice_number            22113 non-null  object        \n",
      " 7   tax_invoice_number        14968 non-null  object        \n",
      " 8   so                        38 non-null     object        \n",
      " 9   project                   11989 non-null  object        \n",
      " 10  rev_con                   1 non-null      object        \n",
      " 11  cn_number                 598 non-null    object        \n",
      " 12  cn_comment                436 non-null    object        \n",
      " 13  invoice_type              22113 non-null  object        \n",
      " 14  invoice_type_description  22113 non-null  object        \n",
      " 15  cust_code                 22113 non-null  object        \n",
      " 16  cust_name                 22113 non-null  object        \n",
      " 17  industry_new              17190 non-null  object        \n",
      " 18  sector                    17190 non-null  object        \n",
      " 19  abbrevation               17190 non-null  object        \n",
      " 20  sale_code                 22113 non-null  int64         \n",
      " 21  sale_name                 22113 non-null  object        \n",
      " 22  invoice_amount            22113 non-null  float64       \n",
      " 23  total_cost                22113 non-null  float64       \n",
      " 24  margin_amount             22113 non-null  float64       \n",
      " 25  margin_percent            22113 non-null  float64       \n",
      " 26  creation_date             22113 non-null  datetime64[ns]\n",
      " 27  created_by                22113 non-null  int64         \n",
      " 28  last_update_date          22113 non-null  datetime64[ns]\n",
      " 29  last_updated_by           22113 non-null  int64         \n",
      " 30  ImportedAt                22113 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](5), float64(4), int64(5), object(17)\n",
      "memory usage: 5.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_trx_id</th>\n",
       "      <th>org_id</th>\n",
       "      <th>gl_date</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>dept_code</th>\n",
       "      <th>invoice_number</th>\n",
       "      <th>tax_invoice_number</th>\n",
       "      <th>so</th>\n",
       "      <th>project</th>\n",
       "      <th>...</th>\n",
       "      <th>sale_name</th>\n",
       "      <th>invoice_amount</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>margin_amount</th>\n",
       "      <th>margin_percent</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>created_by</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>last_updated_by</th>\n",
       "      <th>ImportedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>775892</td>\n",
       "      <td>81</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>SBS</td>\n",
       "      <td>0402</td>\n",
       "      <td>122000109</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Admin-ES, Miss</td>\n",
       "      <td>509550.00</td>\n",
       "      <td>509550.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2020-04-22 11:27:34</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-28 12:57:00</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-30 11:43:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>789836</td>\n",
       "      <td>81</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>ES</td>\n",
       "      <td>0305</td>\n",
       "      <td>222001935</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>190447</td>\n",
       "      <td>...</td>\n",
       "      <td>Chayanan Tonpromram, Miss</td>\n",
       "      <td>201069.44</td>\n",
       "      <td>91731.99</td>\n",
       "      <td>109337.45</td>\n",
       "      <td>54.38</td>\n",
       "      <td>2020-09-21 11:24:37</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-28 12:57:00</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-30 11:43:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813805</td>\n",
       "      <td>81</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>ES</td>\n",
       "      <td>0302</td>\n",
       "      <td>222101558</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>210408</td>\n",
       "      <td>...</td>\n",
       "      <td>Yanumat  Veerabongkotmanee, Miss</td>\n",
       "      <td>3590000.00</td>\n",
       "      <td>3045500.00</td>\n",
       "      <td>544500.00</td>\n",
       "      <td>15.17</td>\n",
       "      <td>2021-05-19 14:38:42</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-28 12:57:00</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-30 11:43:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>817368</td>\n",
       "      <td>81</td>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>ES</td>\n",
       "      <td>0302</td>\n",
       "      <td>222102024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>210557</td>\n",
       "      <td>...</td>\n",
       "      <td>MONGKOL THUNGHIRUNVIMON, Mr.</td>\n",
       "      <td>58500.00</td>\n",
       "      <td>55900.00</td>\n",
       "      <td>2600.00</td>\n",
       "      <td>4.44</td>\n",
       "      <td>2021-07-08 19:10:00</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-28 12:57:00</td>\n",
       "      <td>1152</td>\n",
       "      <td>2023-05-30 11:43:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>828762</td>\n",
       "      <td>81</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>ES</td>\n",
       "      <td>0305</td>\n",
       "      <td>222103791</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>210766</td>\n",
       "      <td>...</td>\n",
       "      <td>Ekarat Yuvajati,</td>\n",
       "      <td>98130.84</td>\n",
       "      <td>84974.00</td>\n",
       "      <td>13156.84</td>\n",
       "      <td>13.41</td>\n",
       "      <td>2021-12-14 12:20:32</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-28 12:57:00</td>\n",
       "      <td>1071</td>\n",
       "      <td>2023-05-30 11:43:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_trx_id  org_id    gl_date invoice_date dept_name dept_code   \n",
       "0           775892      81 2020-04-22   2020-04-22       SBS      0402  \\\n",
       "1           789836      81 2020-09-21   2020-09-21        ES      0305   \n",
       "2           813805      81 2021-05-19   2021-05-19        ES      0302   \n",
       "3           817368      81 2021-07-08   2021-07-08        ES      0302   \n",
       "4           828762      81 2021-12-14   2021-12-14        ES      0305   \n",
       "\n",
       "  invoice_number tax_invoice_number    so project  ...   \n",
       "0      122000109               None  None    None  ...  \\\n",
       "1      222001935               None  None  190447  ...   \n",
       "2      222101558               None  None  210408  ...   \n",
       "3      222102024               None  None  210557  ...   \n",
       "4      222103791               None  None  210766  ...   \n",
       "\n",
       "                          sale_name invoice_amount  total_cost margin_amount   \n",
       "0                    Admin-ES, Miss      509550.00   509550.00          0.00  \\\n",
       "1         Chayanan Tonpromram, Miss      201069.44    91731.99     109337.45   \n",
       "2  Yanumat  Veerabongkotmanee, Miss     3590000.00  3045500.00     544500.00   \n",
       "3      MONGKOL THUNGHIRUNVIMON, Mr.       58500.00    55900.00       2600.00   \n",
       "4                  Ekarat Yuvajati,       98130.84    84974.00      13156.84   \n",
       "\n",
       "  margin_percent       creation_date created_by    last_update_date   \n",
       "0           0.00 2020-04-22 11:27:34       1071 2023-05-28 12:57:00  \\\n",
       "1          54.38 2020-09-21 11:24:37       1071 2023-05-28 12:57:00   \n",
       "2          15.17 2021-05-19 14:38:42       1071 2023-05-28 12:57:00   \n",
       "3           4.44 2021-07-08 19:10:00       1071 2023-05-28 12:57:00   \n",
       "4          13.41 2021-12-14 12:20:32       1071 2023-05-28 12:57:00   \n",
       "\n",
       "  last_updated_by          ImportedAt  \n",
       "0            1071 2023-05-30 11:43:35  \n",
       "1            1071 2023-05-30 11:43:35  \n",
       "2            1071 2023-05-30 11:43:35  \n",
       "3            1152 2023-05-30 11:43:35  \n",
       "4            1071 2023-05-30 11:43:35  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfAll=dfAll.drop(columns=['receipt_number','method_name','application_type']) # receipt\n",
    "#dfAll=dfAll.drop(columns=['customer_trx_id','org_id']) # invoice\n",
    "\n",
    "listColDF=dfAll.columns.tolist()\n",
    "print(listColDF)\n",
    "\n",
    "print(dfAll.info())\n",
    "dfAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "85200a71-7135-44a0-883b-50d64c0a2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfAll.empty:\n",
    "    print(\"No row to import to BQ\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b3f97-ea01-4268-a1af-e23a99793971",
   "metadata": {},
   "source": [
    "# BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83c4a2b7-a91d-4e08-8885-28532591208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(json_credential_file)\n",
    "client = bigquery.Client(credentials=credentials, project=projectId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65f21f-dfed-407c-959a-97b7439e0ca9",
   "metadata": {},
   "source": [
    "## Creaste bigquery schema from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55493758-3f7a-4625-9d7e-d8eef8919d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SchemaField('customer_trx_id', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('org_id', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('gl_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('invoice_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('dept_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('dept_code', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('invoice_number', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('tax_invoice_number', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('so', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('project', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('rev_con', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('cn_number', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('cn_comment', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('invoice_type', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('invoice_type_description', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('cust_code', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('cust_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('industry_new', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('sector', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('abbrevation', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('sale_code', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('sale_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('invoice_amount', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('total_cost', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('margin_amount', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('margin_percent', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('creation_date', 'DATETIME', 'NULLABLE', None, None, (), None), SchemaField('created_by', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('last_update_date', 'DATETIME', 'NULLABLE', None, None, (), None), SchemaField('last_updated_by', 'INTEGER', 'NULLABLE', None, None, (), None), SchemaField('ImportedAt', 'DATETIME', 'NULLABLE', None, None, (), None)]\n"
     ]
    }
   ],
   "source": [
    "# schema = [\n",
    "# bigquery.SchemaField(\"CUSTOMER_TRX_ID\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "# bigquery.SchemaField(\"GL_DATE\", \"DATE\", mode=\"NULLABLE\"),\n",
    "# bigquery.SchemaField(\"DEPT_NAME\", \"STRING\", mode=\"NULLABLE\"),      \n",
    "# bigquery.SchemaField(\"INVOICE_AMOUNT\", \"FLOAT\", mode=\"NULLABLE\"),    \n",
    "# bigquery.SchemaField(\"LAST_UPDATE_DATE\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "# ]\n",
    "\n",
    "schema = []\n",
    "srCols=dfAll.dtypes\n",
    "for name, type_name in srCols.items():\n",
    "    # print(name,type_name)\n",
    "    if str(type_name) in ['int32','int64']:\n",
    "      schema.append(bigquery.SchemaField(name, \"INTEGER\"))\n",
    "    elif str(type_name) =='float64':\n",
    "      schema.append(bigquery.SchemaField(name, \"FLOAT\"))\n",
    "    elif str(type_name) =='datetime64[ns]':\n",
    "      if name in   dateCols:\n",
    "         schema.append(bigquery.SchemaField(name,  \"DATE\"))\n",
    "      else:\n",
    "         schema.append(bigquery.SchemaField(name,  \"DATETIME\"))\n",
    "    else:\n",
    "       schema.append(bigquery.SchemaField(name,  \"STRING\")) \n",
    "      \n",
    "print(schema)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99618a47-0801-4b6a-bd7b-f99bf641b98b",
   "metadata": {},
   "source": [
    "## Check whether dataframe and bigquery schema are the same\n",
    "\n",
    "## Check Existing DataSet and Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "275cd71b-985f-41a5-933c-c4020cb73336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MIS_BI_DW already exists\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "try:\n",
    "    dataset = client.get_dataset(f\"{projectId}.{dataset_id}\")\n",
    "    print(\"Dataset {} already exists\".format(dataset_id))\n",
    "\n",
    "except Exception as ex:\n",
    "    raise(\"Dataset {} is not found\".format(dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c811b4ff-ecda-468d-b5fc-9b16018c516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table():\n",
    "    table = bigquery.Table(table_id,schema=schema)\n",
    "    if  partitionCol!=\"\":\n",
    "     table.time_partitioning = bigquery.TimePartitioning(\n",
    "     type_=partitionType,field=partitionCol)\n",
    "    \n",
    "    if len(clusterCols)>0:\n",
    "     table.clustering_fields = clusterCols\n",
    "\n",
    "    table = client.create_table(table) \n",
    "    print(\n",
    "        \"Created new table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81539c6e-49db-49e9-b5e4-19a98d9fca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_same_schema(listFieldBQ,partitionNameBQ,partitionTypeBQ,clusterBQ,dateTypeBQ):\n",
    "def check_same_schema():\n",
    "    print(\"===============================================================================================\")\n",
    "    print(\"Check every columns name and partition cluster and date type column on table against dataframe\")\n",
    "    def find_difference(dfX,bqX):\n",
    "        intersec_DF_BQ = [set(dfX).symmetric_difference(set(bqX))]\n",
    "        list_DF_BQ=[]\n",
    "        if len(intersec_DF_BQ)>0:\n",
    "         for item in intersec_DF_BQ:\n",
    "            list_DF_BQ=list_DF_BQ+list(item)\n",
    "        return list_DF_BQ \n",
    "        \n",
    "    listColumnX=find_difference(listColDF,listFieldBQ)\n",
    "    if len(listColumnX)>0:\n",
    "        e=f\"Columns: {listColumnX} are NOT THE SAME on BigQuery and ViewTable {source_name} of Oracle\"\n",
    "        listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)])\n",
    "    else:\n",
    "        print(\"All Fields on BQ and DF are ok.\")\n",
    "        \n",
    "        \n",
    "    # PartitionName\n",
    "    if partitionNameBQ!=partitionCol:\n",
    "        e=f\"Partition Column :{partitionNameBQ} in BQ is NOT THE SAME as {partitionCol} defined on ETL Config on Web Admin\"\n",
    "        listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)])\n",
    "    else:\n",
    "        print(\"Partition Name Fields on BQ and DF is ok.\")    \n",
    "        \n",
    "\n",
    "    # # PartitionDateType\n",
    "    if partitionTypeBQ!=partitionType:\n",
    "        e=f\"Partition Date Type :{partitionTypeBQ} in BQ is NOT THE SAME as {partitionType} defined on ETL Config on Web Admin\"\n",
    "        listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)])\n",
    "    \n",
    "    # Cluster List\n",
    "    listClusterX=find_difference(clusterCols,clusterBQ)\n",
    "    if len( listClusterX)>0:\n",
    "        e=f\"Cluster columns : {listClusterX} are NOT THE SAME on BigQuery and ETL Config on Web Admin\"\n",
    "        listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)])\n",
    "    else:\n",
    "        print(\"All Cluster on BQ and DF are ok.\")\n",
    "    \n",
    "    # Date Type List\n",
    "    \n",
    "        # Cluster List\n",
    "    listDateColX=find_difference(dateCols,dateTypeBQ)\n",
    "    if len( listDateColX)>0:\n",
    "        e=f\"Date columns : {listDateColX} are NOT THE SAME on BigQuery and ETL Config on Web Admin\"\n",
    "        listError.append([datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),dtStr_imported,source_name,str(e)])\n",
    "    else:\n",
    "        print(\"All Date Column on BQ and DF are ok.\")\n",
    "\n",
    "\n",
    "    if len(listError)>0:\n",
    "        logErrorMessage(listError)\n",
    "        # delete table\n",
    "        # set isLoading=True to load all data\n",
    "        \n",
    "#       isLoadingAllItems=True\n",
    "#       start_date_query=init_date_query\n",
    "\n",
    "#       print(\"ReLoad Data due to something in schema changed\")  \n",
    "#       dfAll=loadData(isLoadingAllItems)\n",
    "#       print(dfAll.info())  \n",
    "\n",
    "#       print(\"Delete table and re-create new one.\")\n",
    "#       client.delete_table(table_id, not_found_ok=True)  \n",
    "#       create_table()\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df2a0173-bf96-4181-bde8-a9d9c140e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new table mismgntdata-bigquery.MIS_BI_DW.yip_invoice_monthly\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# table    \n",
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    # if no table it will call create_table\n",
    "    \n",
    "    listFieldBQ=[field.name for field in table.schema]\n",
    "    \n",
    "    # required field\n",
    "    partitionNameBQ=table.time_partitioning.field\n",
    "    partitionTypeBQ=table.partitioning_type\n",
    "\n",
    "    clusterBQ=table.clustering_fields\n",
    "    if clusterBQ is None : clusterBQ =[]\n",
    "        \n",
    "    dateTypeBQ=[field.name for field in table.schema if field.field_type=='DATE']\n",
    "    \n",
    "    \n",
    "    print(f\"All Fields : {listFieldBQ}\")\n",
    "    print(f\"Partiton Field&Type: {partitionNameBQ} - {partitionTypeBQ}\")\n",
    "    print(f\"Cluster Field List: {clusterBQ}\")\n",
    "    print(f\"Date Field List: {dateTypeBQ}\")\n",
    "    \n",
    "    #check_same_schema(listFieldBQ,partitionNameBQ,partitionTypeBQ,clusterBQ,dateTypeBQ)\n",
    "    check_same_schema()\n",
    "        \n",
    "except Exception as ex:\n",
    "    create_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac562df-e933-4563-96f8-6db9af10ad1d",
   "metadata": {},
   "source": [
    "# To load data into BQ , technically you need  to save it as CSV file first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b278c1c-50ed-446a-9e1a-11129557fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22113 rows are about to be imported to BQ\n"
     ]
    }
   ],
   "source": [
    "if dfAll.empty==False:\n",
    "    no_rows=len(dfAll)\n",
    "    print(f\"{no_rows} rows are about to be imported to BQ\")\n",
    "    dfAll.to_csv (temp_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9425d0-984d-4446-a353-7bb916da82e2",
   "metadata": {},
   "source": [
    "# Load data from CSV file to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e74bd60-ed17-4269-8524-f82bf422b91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22113 rows and 31 columns to mismgntdata-bigquery.MIS_BI_DW.yip_invoice_monthly\n"
     ]
    }
   ],
   "source": [
    "# if isLoadingAllItems==False:\n",
    "# print(\"Load with appending\")\n",
    "\n",
    "# Addtional Try Error\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1,\n",
    "    autodetect=False,write_disposition=\"WRITE_APPEND\"\n",
    "    )\n",
    "# else:\n",
    "#     print(\"Load with all data\")\n",
    "#     job_config = bigquery.LoadJobConfig(\n",
    "#         source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1,\n",
    "#         autodetect=False,write_disposition=\"WRITE_TRUNCATE\"\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "with open(temp_path, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_id, job_config=job_config)\n",
    "job.result()  # Waits for the job to complete.\n",
    "\n",
    "table = client.get_table(table_id)  # Make an API request.\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        no_rows, len(table.schema), table_id\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c93e0-eb5b-43db-9296-7e7ab1b66a43",
   "metadata": {},
   "source": [
    "# Create Transation and delete csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf4ca4b4-7085-4384-b8ea-655426dc3850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ETL Trasaction\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Addtional Try Error    \n",
    "def insertETLTrans(recordList):\n",
    "    try:\n",
    "        sqliteConnection = sqlite3.connect(os.path.abspath(data_base_file))\n",
    "        cursor = sqliteConnection.cursor()\n",
    "        sqlite_insert_query = \"\"\"\n",
    "        INSERT INTO etl_transaction\n",
    "        (etl_datetime, data_source_id,no_rows,is_load_all)  VALUES (?,?,?,?);\n",
    "         \"\"\"\n",
    "\n",
    "        cursor.executemany(sqlite_insert_query, recordList)\n",
    "        print(\"Done ETL Trasaction\")\n",
    "        sqliteConnection.commit()\n",
    "        cursor.close()\n",
    "\n",
    "    except sqlite3.Error as error:\n",
    "        print(\"Failed to insert etl_transaction table\", error)\n",
    "    finally:\n",
    "        if sqliteConnection:\n",
    "            sqliteConnection.close()\n",
    "            \n",
    "\n",
    "\n",
    "if isLoadingAllItems==True:\n",
    "    is_load_all=1\n",
    "else:\n",
    "    is_load_all=0\n",
    "\n",
    "dfETFTran=pd.DataFrame.from_records([{'etl_datetime':dtStr_imported,'data_source_id':source_name,'no_rows':no_rows,'is_load_all':is_load_all}])\n",
    "recordsToInsert=list(dfETFTran.to_records(index=False))\n",
    "insertETLTrans(recordsToInsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2e88468-f281-4385-bfab-472b0e65aa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted temp/yip_invoice_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "#Addtional Try Error\n",
    "if os.path.exists(temp_path):\n",
    "  os.remove(temp_path)\n",
    "  print(f\"Deleted {temp_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "de3e6c80-0ead-4bc2-a08d-e1b9ed2bc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if any error , send mail to adminstrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc1aaf-bfc3-466c-aa61-7684f7f351c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
